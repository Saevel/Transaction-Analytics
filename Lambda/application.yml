version: "3"

networks:
    lambda-network:
        driver: overlay

services:

    speed-layer:
      image: saevel/transaction-analytics-lambda-speed-layer
      deploy:
        replicas: 1
        restart_policy:
          condition: on-failure
      ports:
      - 9990:9990
      networks:
      - lambda-network

    # TODO: Add the method to deploy batch layer with a cron.

    # Spark Master
    spark-master:
        image: fsoppelsa/spark-master
        environment:
            - SPARK_MASTER_IP=0.0.0.0
        deploy:
          replicas: 1
          update_config:
            parallelism: 1
            delay: 10s
          restart_policy:
            condition: on-failure
        ports:
          - 8080:8080
          - 7077:7077
          - 6066:6066
        networks:
          - lambda-network

    # Spark Worker
    spark-worker:
        image: fsoppelsa/spark-worker
        environment:
        - SPARK_MASTER_IP=spark-master
        depends_on:
        - spark-master
        deploy:
          replicas: 3
          update_config:
            parallelism: 1
            delay: 10s
          restart_policy:
            condition: on-failure
        networks:
          - lambda-network

    # HDFS NAMENODE
    hdfs-namenode:
        image: sfedyakov/hadoop-271-cluster
        hostname: namenode
        ports:
          - 8088:8088
          - 50090:50090
          - 19888:19888
        command: "/etc/bootstrap.sh -d -namenode"
        deploy:
            restart_policy:
                condition: on-failure
        networks:
        - lambda-network

    # HDFS DATANODE
    hdfs-datanode:
        depends_on:
        - namenode
        image: sfedyakov/hadoop-271-cluster
        command: "/etc/bootstrap.sh -d -datanode"
        deploy:
            replicas: 3
            restart_policy:
                condition: on-failure
        networks:
        - lambda-network