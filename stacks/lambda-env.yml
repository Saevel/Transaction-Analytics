version: "3"

networks:
    lambda-env-network:
        driver: overlay

services:
    # Spark
    spark-master:
        image: fsoppelsa/spark-master
        environment:
            - SPARK_MASTER_IP=0.0.0.0
        deploy:
          replicas: 1
          update_config:
            parallelism: 1
            delay: 10s
          restart_policy:
            condition: on-failure
        ports:
          - 8080:8080
          - 7077:7077
          - 6066:6066
        networks:
          - lambda-env-network

    spark-worker:
        image: fsoppelsa/spark-worker
        environment:
        - SPARK_MASTER_IP=spark-master
        depends_on:
        - spark-master
        deploy:
          replicas: 3
          update_config:
            parallelism: 1
            delay: 10s
          restart_policy:
            condition: on-failure
        networks:
          - lambda-env-network

    # HDFS NAMENODE
    hdfs-namenode:
        image: sfedyakov/hadoop-271-cluster
        hostname: namenode
        ports:
          - 8088:8088
          - 50090:50090
          - 19888:19888
        command: "/etc/bootstrap.sh -d -namenode"
        deploy:
            restart_policy:
                condition: on-failure
        networks:
        - lambda-env-network

    # HDFS DATANODE
    hdfs-datanode:
        depends_on:
        - namenode
        image: sfedyakov/hadoop-271-cluster
        command: "/etc/bootstrap.sh -d -datanode"
        deploy:
            replicas: 3
            restart_policy:
                condition: on-failure
        networks:
        - lambda-env-network